{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Lambda\n",
    "from keras.layers import AveragePooling2D, Input, Activation\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers.merge import Add\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "SEED = 666\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, y_train), (x_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train     = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test      = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "    \n",
    "    chan_axis = 1\n",
    "    row_axis  = 2\n",
    "    col_axis  = 3\n",
    "else:\n",
    "    x_train     = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test      = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "    row_axis  = 1\n",
    "    col_axis  = 2\n",
    "    chan_axis = 3\n",
    "    \n",
    "x_train  = x_train.astype('float32')\n",
    "x_test   = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test  /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for showing particular image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_img(x_tab, y_tab, num):\n",
    "    plt.title('Label is {label}'.format(label=y_tab[num]))\n",
    "    plt.imshow(x_tab[num].reshape((img_cols, img_rows)), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAEICAYAAABMNAHBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd78bcb82e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = np.random.randint(0, len(x_train))\n",
    "\n",
    "print_img(x_train, y_train, example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flipping images along y axis (later I've chosen to instead use ImageDataGenerator from Keras):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_flip = np.copy(x_train)\n",
    "y_train_flip = np.copy(y_train)\n",
    "\n",
    "for i in range(len(x_train_flip)):\n",
    "    x_train_flip[i] = np.flip(x_train_flip[i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAEICAYAAABMNAHBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZpZySJhZ6v8BUaTEHKL3eFIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f426eedee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAEICAYAAABMNAHBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEyZJREFUeJzt3X+s3XV9x/Hni/6g9hctdGW3LS2W\nikSdwkKQbMSVoY6RLcUsoE3MatSUJbBpwozQhdEx2YxBYWYJro6OqlNE+dGuuiGR1mqMyi3hR7FW\nfqSUwqWlFGjLr0L73h/ne/Fwud/39/acc8/50r4eyc29/b7P53M+58u9L74/Pt/vVxGBmVmZo3o9\nADOrN4eEmaUcEmaWckiYWcohYWYph4SZpRwSZpbqekhIWi/p051uK2mZpP9soc+Q9IKkq1sZk9lb\nlaS7JL0s6WfZ61oOCUlbJX2w1fadFhH/EhEthQ/wvoj4h7KipHMk/UbSi5LWSZrX4vu4r8OgL0nj\nJX2/+BsISQtbHVPR36mSNhbj2ijp1G70FRF/CvxNVZ/e3aggaQZwK3AFcCzQD3zXfR25fRV+Bnwc\neKqNPpA0HlgNfAuYDqwCVhfLe9bXG0RES1/AVuCDwyyfDqwFngaeLX6e01RfD/wr8Cvg+eJDHdtU\nPxP4OfAccB+wcEjbT5eMZznwreLnCcWKeqbo527g+JJ2ASxIPudS4OdN/54EvASc0sI6c1+HQV9D\n+t3e/DvaQvsPA08Aalq2DTi3G30BnwB+lvU7GlsSRwH/BcwD5hb/If59yGv+GvgkMAt4DfgqgKTZ\nwA+AL9BI+78HbpH0e4c4hiXAMcAJwHE0NqleauGzALybRlgBEBEvAI8Uy93XkdlXJ70buD+Kv9jC\n/bT+GTvV1+s6HhIR8UxE3BIRL0bEXuBq4E+GvOybEbGp+A91BXChpDE0Nt9+GBE/jIiDEXEnjc3C\n8w5xGK/SCIcFEXEgIjZGxJ4WP9JkGls8zZ4HprivI7avTqr9Z+x4SEiaKOk/JD0maQ+wAZhWhMCg\nx5t+fgwYB8ygsfVxgaTnBr+As4C+QxzGN4E7gJskPSnpS5LGtfiR9gFThyybCux1X0dsX51U+884\nGrsblwLvBN4fEVOBDxTL1fSaE5p+nkvj//y7aITHNyNiWtPXpIj44qEMICJejYh/ioh3AX8E/AWN\nXZxWPAi8b/AfkiYBJxXL3deR2VcnPQi8V1Lz38d7af0zdqqv17UbEuMkTWj6Gktj0+Yl4DlJxwJX\nDtPu45LeJWkicBXw/Yg4QONg419K+jNJY4o+F0qacyiDknS2pD8otl720AihAy1+xtuA90j6K0kT\ngH+ksd/3G/d1xPaFpKOLfgDGF7+rShsNbz2N382/K/q8pFh+V4/7+p02jspupXFmoPnrCzQORq6n\nsenzW+Cioja2aLee353d2AP8DzCjqd/3Az8BdtM4Q/IDYG5T25Gc3VgMbAFeAHbQODA6tqRdenaj\neM0Hgd/QCL/1wIlNta8BXzuE9ea+Do++hvv9P7GoLQP+9xD6Og3YWIzrHuC0ptqo9sUIzm6oeOER\nS9LLwCvAVyPiil6Px6xbJN1JY8rBryLinNLXHekhYWY5z7g0s5RDwsxSY7v5ZpK8b2M2yiKilbMs\npdrakpB0rqQtkh6WdFmnBmVm9dHygctiDsJvgQ/RuMjlbmBxRPw6aeMtCbNRVqctiTOAhyPi0YjY\nD9wELOrMsMysLtoJidm88RqM7cWyN5C0VFK/pP423svMeqSdA5fDbdK8aXciIlYAK8C7G2ZvRe1s\nSWznjRdqzQGebG84ZlY37YTE3cA7JL29uD3Wx4A1nRmWmdVFy7sbEfFacZXZHcAYYGVE9PqyWzPr\nsK5eu+FjEmajr06nQM3sCOCQMLOUQ8LMUg4JM0s5JMws5ZAws5RDwsxSDgkzSzkkzCzlkDCzlEPC\nzFIOCTNLOSTMLOWQMLOUQ8LMUg4JM0s5JMws5ZAws5RDwsxSDgkzSzkkzCzlkDCzlEPCzFIOCTNL\nOSTMLOWQMLOUQ8LMUg4JM0s5JMws5ZAws9TYdhpL2grsBQ4Ar0XE6Z0YlJnVR1shUTg7InZ1oB8z\nqyHvbphZqt2QCOBHkjZKWjrcCyQtldQvqb/N9zKzHlBEtN5YmhURT0qaCdwJ/G1EbEhe3/qbmdmI\nRIQ62V9bWxIR8WTxfSdwG3BGJwZlZvXRckhImiRpyuDPwIeBTZ0amJnVQztnN44HbpM02M+3I+L/\nOjIqM6uNto5JHPKb+ZiE2air1TEJMzv8OSTMLOWQMLOUQ8LMUg4JM0s5JMws5ZAws5RDwsxSDgkz\nSzkkzCzlkDCzlEPCzFIOCTNLdeJGuLVw1FF53hWXtJequhr24MGDLfddpeq9lyxZktbnzZtXWrvq\nqqtaGtOgqs/Wznrt5hXI1jpvSZhZyiFhZimHhJmlHBJmlnJImFnKIWFmKYeEmaVqdbfsT33qU2n7\n/v7yJwXed999rQ3qLWDLli1pffLkyaW1Rx99NG176623pvVrr702rfdSu3NfDle+W7aZdZVDwsxS\nDgkzSzkkzCzlkDCzlEPCzFIOCTNL1WqeRNVYnn766dLaunXr0rbLli1L64888khaH02XX355Wl+6\ndGlaHxgYKK1NmjQpbTt37ty0vm3btrR+0003pfXrrruutPbSSy+lba01XZ8nIWmlpJ2SNjUtO1bS\nnZIeKr5P7+SgzKw+RrK7cSNw7pBllwE/joh3AD8u/m1mh6HKkIiIDcDuIYsXAauKn1cB53d4XGZW\nE63e4/L4iBgAiIgBSTPLXihpKZDvVJtZbY36jXAjYgWwAqoPXJpZ/bR6CnSHpD6A4vvOzg3JzOqk\n1ZBYAwze530JsLozwzGzuqmcJyHpO8BCYAawA7gSuB24GZgLbAMuiIihBzffZOrUqXHmmWeW1q+/\n/vq0/c6d5RssCxYsSNtOmzYtrWdzMCCfL1A1F+Hkk09O6/v370/rjz32WFrP3v/VV19t672nTJmS\n1seMGZPWs/V+4403pm2XL1+e1p955pm0nhnN54lA9XNgsue4tDt3qdPzJCqPSUTE4pLSOZ0ciJnV\nk6dlm1nKIWFmKYeEmaUcEmaWckiYWaqrl4rPmTMnLr744tL65z73ubR9djl31WXHVae0qk5jTpw4\nsbS2d+/etG3VacjslvhQPbYXXnihtFb13/eVV15J6y+++GJaz9YLwLhx40pr7X7uNWvWpPVLL720\ntPbUU0+lbUdbdoq06r/ZCOq+pb6ZdY9DwsxSDgkzSzkkzCzlkDCzlEPCzFIOCTNLjfqdqZqNHz+e\nefPmldYPHDiQtp8wYUJpbdasWWnbqnPLzz//fFrP5llMnTo1bZvNFYDqeRRVcxWyy46r5oe87W1v\na+u9q+ZZZGOrWudV8yTOPvvstP7QQw+V1qouU7/99tvT+pYtW9L6s88+m9azuS114y0JM0s5JMws\n5ZAws5RDwsxSDgkzSzkkzCzlkDCzVFfnSUQEr732Wmm9ap5ENp/gueeeS9tW3Tq+aq7Dyy+/XFrL\nPhNUzyWoMn78+LSePWpg3759adtTTjklrc+ePTutV93WPht71RyNqvt0VN0TIpuLsGjRorTt4sVl\nN4lvqJp3M3Zs/qe1devW0toVV1yRtl27dm1a7zRvSZhZyiFhZimHhJmlHBJmlnJImFnKIWFmKYeE\nmaW6Ok+iStVj7LP7C1Q9w6FqDkY79zao6rvqnHnVPR+qzJ8/v7RWdV+D7PkPUD0foOp5J5mquSlT\npkxJ61XrPatXzZvJ7oMB1b+rVeu1r6+vtLZy5cq07eWXX15aW716ddq2FZVbEpJWStopaVPTsuWS\nnpB0b/F1XsdHZma1MJLdjRuBc4dZfm1EnFp8/bCzwzKzuqgMiYjYAOzuwljMrIbaOXB5iaT7i92R\n6WUvkrRUUr+k/qq5+GZWP62GxPXAScCpwADw5bIXRsSKiDg9Ik6vOhBlZvXTUkhExI6IOBARB4Gv\nA2d0dlhmVhcthYSk5vM3HwE2lb3WzN7aKudJSPoOsBCYIWk7cCWwUNKpQABbgYtG8mb79+9Pr6Ov\nmi+QHdOomg/Q7nnvXbt2ldaOPvrotO3EiRPTetV9FarWSzYPY+bMmWnbqvkCe/bsSetVz8Y47rjj\nSmtV67xK1fNKsjkeVeu0ap5D1fNIqu4xsmPHjtLaggUL0rYf/ehHS2sbNmxI27aiMiQiYri7b9zQ\n8ZGYWS15WraZpRwSZpZySJhZyiFhZimHhJmlunqp+P79+9m2bVtpverW8XPmzCmtVV3qXXUqr+pU\nYFavuly6ndvOV7035Kf6qi5Trzo13M5pRoDdu8sv+6k6TdjOZeiQj320H3Mwb968tH7yySeX1o45\n5pi07V133VVaG41LH7wlYWYph4SZpRwSZpZySJhZyiFhZimHhJmlHBJmllLVee6OvpmUvtk555yT\ntj/jjPJ722Q1gFmzZqX1adOmpfXs0uGqW7tXXUpe9TiACRMmpPVsbO1ejt3uowiyOSLZ5fdQPY+i\nar1mt+yfPXt22rZqnY8bN66ten9/f2ntmmuuSdt+73vfS+sR0d4zGobwloSZpRwSZpZySJhZyiFh\nZimHhJmlHBJmlnJImFmqVvMkbHhVcziy+QBVczDmz5/fVr3q9u99fX2ltRkzZqRtq257X3VPiKw+\nMDCQtv3FL36R1h9//PG0vm7durReNf+kHZ4nYWZd5ZAws5RDwsxSDgkzSzkkzCzlkDCzlEPCzFKV\n8yQknQB8A/h94CCwIiL+TdKxwHeBE4GtwIUR8WxFX54nYTbKOj1PYiQh0Qf0RcQ9kqYAG4HzgU8A\nuyPii5IuA6ZHxOcr+nJImI2yrk+mioiBiLin+HkvsBmYDSwCVhUvW0UjOMzsMHNIxyQknQicBvwS\nOD4iBqARJMDMTg/OzHpvxM8ClTQZuAX4bETsqZpX39RuKbC0teGZWa+N6AIvSeOAtcAdEfGVYtkW\nYGFEDBTHLdZHxDsr+vExCbNR1vVjEmpsMtwAbB4MiMIaYEnx8xJgdScHZmb1MJKzG2cBPwUeoHEK\nFGAZjeMSNwNzgW3ABRFR/px5vCVh1g1dPwXa0TdzSJiNOt9Pwsy6yiFhZimHhJmlHBJmlnJImFnK\nIWFmKYeEmaUcEmaWckiYWcohYWYph4SZpRwSZpZySJhZyiFhZimHhJmlHBJmlnJImFnKIWFmKYeE\nmaUcEmaWckiYWcohYWYph4SZpRwSZpZySJhZyiFhZimHhJmlHBJmlnJImFnKIWFmqcqQkHSCpHWS\nNkt6UNJniuXLJT0h6d7i67zRH66ZdZsiIn+B1Af0RcQ9kqYAG4HzgQuBfRFxzYjfTMrfzMzaFhHq\nZH9jR/CGA8BA8fNeSZuB2Z0chJnV1yEdk5B0InAa8Mti0SWS7pe0UtL0kjZLJfVL6m9rpGbWE5W7\nG6+/UJoM/AS4OiJulXQ8sAsI4J9p7JJ8sqIP726YjbJO726MKCQkjQPWAndExFeGqZ8IrI2I91T0\n45AwG2WdDomRnN0QcAOwuTkgigOagz4CbOrkwMysHkZyduMs4KfAA8DBYvEyYDFwKo3dja3ARcVB\nzqwvb0mYjbKe7G507M0cEmajruu7G2Z2ZHNImFnKIWFmKYeEmaUcEmaWckiYWcohYWYph4SZpRwS\nZpZySJhZyiFhZimHhJmlHBJmlnJImFmq8ka4HbYLeKzp3zOKZXVU17HVdVzgsbWqk2Ob16F+XtfV\n+0m86c2l/og4vWcDSNR1bHUdF3hsrarz2MC7G2ZWwSFhZqleh8SKHr9/pq5jq+u4wGNrVZ3H1ttj\nEmZWf73ekjCzmnNImFmqJyEh6VxJWyQ9LOmyXoyhjKStkh6QdG+vn19aPGN1p6RNTcuOlXSnpIeK\n78M+g7VHY1su6Yli3d0r6bweje0ESeskbZb0oKTPFMt7uu6ScdVivZXp+jEJSWOA3wIfArYDdwOL\nI+LXXR1ICUlbgdMjoucTbyR9ANgHfGPwEYqSvgTsjogvFgE7PSI+X5OxLQf2RcQ13R7PkLH10Xg2\n7T2SpgAbgfOBT9DDdZeM60JqsN7K9GJL4gzg4Yh4NCL2AzcBi3owjtqLiA3A7iGLFwGrip9X0fgl\n67qSsdVCRAxExD3Fz3uBzcBserzuknHVWi9CYjbweNO/t1OvFRXAjyRtlLS014MZxvGDj1Msvs/s\n8XiGukTS/cXuSE92hZoVD7M+DfglNVp3Q8YFNVtvzXoREsM9gqxO52H/OCL+EPhz4OJis9pG5nrg\nJBrPiB0AvtzLwUiaDNwCfDYi9vRyLM2GGVet1ttQvQiJ7cAJTf+eAzzZg3EMKyKeLL7vBG6jsXtU\nJzsGn+hefN/Z4/G8LiJ2RMSBiDgIfJ0erjtJ42j8If53RNxaLO75uhtuXHVab8PpRUjcDbxD0tsl\njQc+BqzpwTjeRNKk4oASkiYBHwY25a26bg2wpPh5CbC6h2N5g8E/wMJH6NG6kyTgBmBzRHylqdTT\ndVc2rrqstzI9mXFZnOK5DhgDrIyIq7s+iGFImk9j6wEal9F/u5djk/QdYCGNS4l3AFcCtwM3A3OB\nbcAFEdH1A4glY1tIY5M5gK3ARYPHALo8trOAnwIPAAeLxcto7P/3bN0l41pMDdZbGU/LNrOUZ1ya\nWcohYWYph4SZpRwSZpZySJhZyiFhZimHhJml/h9pm+GZanlUyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f426eeb7630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = np.random.randint(0, len(x_train))\n",
    "\n",
    "print_img(x_train, y_train, example)\n",
    "print_img(x_train_flip, y_train_flip, example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train, x_train_flip), axis=0)\n",
    "y_train = np.concatenate((y_train, y_train_flip), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAEICAYAAABMNAHBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f426ee0e748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = np.random.randint(0, len(x_train))\n",
    "\n",
    "print_img(x_train, y_train, example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_evaluate(model, x_tab_tr, y_tab_tr, x_tab_te, y_tab_te, epochs, batch):\n",
    "    model.fit(x_tab_tr, y_tab_tr, epochs=epochs, batch_size=batch, validation_data=(x_tab_te, y_tab_te))#, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_fold(model_func, n_folds, x_tab, y_tab, epochs, batch):\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "    i = 0\n",
    "\n",
    "    for train, test in skf.split(y_tab, np.argmax(y_tab, axis=1)):\n",
    "            print(\"Running Fold %d / %d\" % (i+1, n_folds))\n",
    "            i += 1\n",
    "            cnn = None\n",
    "            cnn = model_func()\n",
    "            train_evaluate(cnn, x_tab[train], y_tab[train], x_tab[test], y_tab[test], epochs, batch)\n",
    "            cnn.optimizer.lr = 0.0001\n",
    "            train_evaluate(cnn, x_tab[train], y_tab[train], x_tab[test], y_tab[test], epochs, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_normalization(x):\n",
    "    mean = x_train.mean().astype(np.float32)\n",
    "    std  = x_train.std().astype(np.float32)\n",
    "    return (x - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(input_normalization, input_shape=input_shape))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axis(=1) out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-aab8c4d084ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-e2778a876dd5>\u001b[0m in \u001b[0;36mk_fold\u001b[0;34m(model_func, n_folds, x_tab, y_tab, epochs, batch)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running Fold %d / %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \"\"\"\n\u001b[0;32m--> 963\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: axis(=1) out of bounds"
     ]
    }
   ],
   "source": [
    "k_fold(basic_cnn, 5, x_train, y_train, 10, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_clone():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Lambda(input_normalization, input_shape=input_shape))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax', name='final_dense'))\n",
    "    \n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 / 5\n",
      "Train on 96000 samples, validate on 24000 samples\n",
      "Epoch 1/10\n",
      "96000/96000 [==============================] - 24s 245us/step - loss: 0.7027 - acc: 0.7538 - val_loss: 2.2540 - val_acc: 0.2858\n",
      "Epoch 2/10\n",
      "96000/96000 [==============================] - 21s 221us/step - loss: 0.3354 - acc: 0.8793 - val_loss: 0.6996 - val_acc: 0.7655\n",
      "Epoch 3/10\n",
      "96000/96000 [==============================] - 21s 221us/step - loss: 0.2676 - acc: 0.9023 - val_loss: 0.3623 - val_acc: 0.8700\n",
      "Epoch 4/10\n",
      "96000/96000 [==============================] - 21s 222us/step - loss: 0.2342 - acc: 0.9151 - val_loss: 0.3788 - val_acc: 0.8739\n",
      "Epoch 5/10\n",
      "96000/96000 [==============================] - 21s 222us/step - loss: 0.2071 - acc: 0.9245 - val_loss: 0.3029 - val_acc: 0.8842\n",
      "Epoch 6/10\n",
      "96000/96000 [==============================] - 21s 222us/step - loss: 0.1867 - acc: 0.9311 - val_loss: 0.3245 - val_acc: 0.8958\n",
      "Epoch 7/10\n",
      "96000/96000 [==============================] - 21s 221us/step - loss: 0.1700 - acc: 0.9387 - val_loss: 0.2207 - val_acc: 0.9218\n",
      "Epoch 8/10\n",
      "96000/96000 [==============================] - 22s 225us/step - loss: 0.1563 - acc: 0.9424 - val_loss: 0.3893 - val_acc: 0.8834\n",
      "Epoch 9/10\n",
      "96000/96000 [==============================] - 22s 225us/step - loss: 0.1456 - acc: 0.9464 - val_loss: 0.1844 - val_acc: 0.9352\n",
      "Epoch 10/10\n",
      "96000/96000 [==============================] - 21s 223us/step - loss: 0.1363 - acc: 0.9498 - val_loss: 0.2048 - val_acc: 0.9294\n",
      "Train on 96000 samples, validate on 24000 samples\n",
      "Epoch 1/10\n",
      "96000/96000 [==============================] - 21s 223us/step - loss: 0.1245 - acc: 0.9540 - val_loss: 0.2544 - val_acc: 0.9186\n",
      "Epoch 2/10\n",
      "96000/96000 [==============================] - 21s 222us/step - loss: 0.1190 - acc: 0.9563 - val_loss: 0.1788 - val_acc: 0.9387\n",
      "Epoch 3/10\n",
      "96000/96000 [==============================] - 21s 222us/step - loss: 0.1104 - acc: 0.9599 - val_loss: 0.2068 - val_acc: 0.9326\n",
      "Epoch 4/10\n",
      "96000/96000 [==============================] - 21s 223us/step - loss: 0.1009 - acc: 0.9633 - val_loss: 0.3559 - val_acc: 0.9024\n",
      "Epoch 5/10\n",
      "96000/96000 [==============================] - 21s 223us/step - loss: 0.0946 - acc: 0.9646 - val_loss: 0.2035 - val_acc: 0.9361\n",
      "Epoch 6/10\n",
      "96000/96000 [==============================] - 22s 226us/step - loss: 0.0864 - acc: 0.9677 - val_loss: 0.2248 - val_acc: 0.9326\n",
      "Epoch 7/10\n",
      "96000/96000 [==============================] - 21s 224us/step - loss: 0.0818 - acc: 0.9699 - val_loss: 0.1897 - val_acc: 0.9430\n",
      "Epoch 8/10\n",
      "96000/96000 [==============================] - 22s 227us/step - loss: 0.0744 - acc: 0.9731 - val_loss: 0.2108 - val_acc: 0.9388\n",
      "Epoch 9/10\n",
      "96000/96000 [==============================] - 22s 226us/step - loss: 0.0703 - acc: 0.9748 - val_loss: 0.2150 - val_acc: 0.9382\n",
      "Epoch 10/10\n",
      "96000/96000 [==============================] - 21s 224us/step - loss: 0.0671 - acc: 0.9756 - val_loss: 0.2297 - val_acc: 0.9379\n",
      "Running Fold 2 / 5\n",
      "Train on 96000 samples, validate on 24000 samples\n",
      "Epoch 1/10\n",
      " 6144/96000 [>.............................] - ETA: 50s - loss: 2.2627 - acc: 0.3174"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-00eec653dddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_clone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-114-2687299501df>\u001b[0m in \u001b[0;36mk_fold\u001b[0;34m(model_func, n_folds, x_tab, y_tab, epochs, batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m#loss, acc =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mtrain_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtrain_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-192ae0ec7d0c>\u001b[0m in \u001b[0;36mtrain_evaluate\u001b[0;34m(model, x_tab_tr, y_tab_tr, x_tab_te, y_tab_te, epochs, batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tab_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tab_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#return model.evaluate(x_tab_te, y_tab_te, verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_fold(vgg_clone, 5, x_train, y_train, 10, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### VGG single model - submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "120000/120000 [==============================] - 27s 222us/step - loss: 0.5898 - acc: 0.7917\n",
      "Epoch 2/10\n",
      "120000/120000 [==============================] - 25s 205us/step - loss: 0.2948 - acc: 0.8932\n",
      "Epoch 3/10\n",
      "120000/120000 [==============================] - 24s 204us/step - loss: 0.2391 - acc: 0.9131\n",
      "Epoch 4/10\n",
      "120000/120000 [==============================] - 24s 204us/step - loss: 0.2099 - acc: 0.9251\n",
      "Epoch 5/10\n",
      "120000/120000 [==============================] - 24s 204us/step - loss: 0.1880 - acc: 0.9321\n",
      "Epoch 6/10\n",
      "120000/120000 [==============================] - 24s 204us/step - loss: 0.1700 - acc: 0.9377\n",
      "Epoch 7/10\n",
      "120000/120000 [==============================] - 25s 205us/step - loss: 0.1568 - acc: 0.9425\n",
      "Epoch 8/10\n",
      "120000/120000 [==============================] - 25s 210us/step - loss: 0.1445 - acc: 0.9469\n",
      "Epoch 9/10\n",
      "120000/120000 [==============================] - 25s 204us/step - loss: 0.1351 - acc: 0.9506\n",
      "Epoch 10/10\n",
      "120000/120000 [==============================] - 25s 205us/step - loss: 0.1237 - acc: 0.9549\n",
      "Epoch 1/5\n",
      "120000/120000 [==============================] - 25s 210us/step - loss: 0.1143 - acc: 0.9580\n",
      "Epoch 2/5\n",
      "120000/120000 [==============================] - 25s 212us/step - loss: 0.1079 - acc: 0.9605\n",
      "Epoch 3/5\n",
      "120000/120000 [==============================] - 25s 205us/step - loss: 0.1004 - acc: 0.9632\n",
      "Epoch 4/5\n",
      "120000/120000 [==============================] - 25s 207us/step - loss: 0.0896 - acc: 0.9671\n",
      "Epoch 5/5\n",
      "120000/120000 [==============================] - 24s 202us/step - loss: 0.0836 - acc: 0.9696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae8c5465f8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vgg_clone()\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=512)\n",
    "model.optimizer.lr = 0.0001\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 ..., 8 1 5]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test)\n",
    "submission = np.argmax(result, axis=1)\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('vgg-submission.csv', 'w') as f:\n",
    "    f.write('Id,Class\\n')\n",
    "    for i, c in enumerate(submission):\n",
    "        f.write('{},{}\\n'.format(i, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WideResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://arxiv.org/pdf/1605.07146.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrn_clone(n=4, k=2, D=0.0):\n",
    "    \n",
    "    def merge(x, y):\n",
    "        x_shape = K.int_shape(x)\n",
    "        y_shape = K.int_shape(y)\n",
    "        stride_w = int(round(x_shape[row_axis] / y_shape[row_axis]))\n",
    "        stride_h = int(round(x_shape[col_axis] / y_shape[col_axis]))\n",
    "        \n",
    "        if x_shape[chan_axis] != y_shape[chan_axis]:\n",
    "            x = Conv2D(filters=y_shape[chan_axis], kernel_size=(1, 1),\n",
    "                             strides=(stride_w, stride_h), padding=\"valid\")(x)\n",
    "        \n",
    "        output = Add()([x, y])\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    \n",
    "    # Conv1 [3x3, 16]\n",
    "    def conv1(x):\n",
    "        output = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "        output = BatchNormalization(axis=chan_axis)(output)\n",
    "        output = Activation('relu')(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    # Conv2 [3 x 3, 16 x k] x 2\n",
    "    def conv2(x, k, d=0.0):\n",
    "        skip = x\n",
    "        \n",
    "        output = BatchNormalization(axis=chan_axis)(x)\n",
    "        output = Activation('relu')(output)\n",
    "        output = Conv2D(16 * k, kernel_size=(3, 3), activation='relu', padding='same')(output)\n",
    "        \n",
    "        output = Dropout(d)(output)\n",
    "        \n",
    "        output = BatchNormalization()(output)\n",
    "        output = Activation('relu')(output)\n",
    "        output = Conv2D(16 * k, kernel_size=(3, 3), activation='relu', padding='same')(output)\n",
    "        \n",
    "        output = merge(skip, output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    # Conv3 [3 x 3, 32 x k] x 2\n",
    "    def conv3(x, k, d=0.0):\n",
    "        skip = x\n",
    "        \n",
    "        output = BatchNormalization(axis=chan_axis)(x)\n",
    "        output = Activation('relu')(output)\n",
    "        output = Conv2D(32 * k, kernel_size=(3, 3), activation='relu', padding='same')(output)\n",
    "        \n",
    "        output = Dropout(d)(output)\n",
    "        \n",
    "        output = BatchNormalization(axis=chan_axis)(output)\n",
    "        output = Activation('relu')(output)\n",
    "        output = Conv2D(32 * k, kernel_size=(3, 3), activation='relu', padding='same')(output)\n",
    "        \n",
    "        output = merge(skip, output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    # Conv4 [3 x 3, 64 x k] x 2\n",
    "    def conv4(x, k, d=0.0):\n",
    "        skip = x\n",
    "        \n",
    "        output = BatchNormalization(axis=chan_axis)(x)\n",
    "        output = Activation('relu')(output)\n",
    "        output = Conv2D(64 * k, kernel_size=(3, 3), activation='relu', padding='same')(output)\n",
    "        \n",
    "        output = Dropout(d)(output)\n",
    "        \n",
    "        output = BatchNormalization(axis=chan_axis)(output)\n",
    "        output = Activation('relu')(output)\n",
    "        output = Conv2D(64 * k, kernel_size=(3, 3), activation='relu', padding='same')(output)\n",
    "        \n",
    "        output = merge(skip, output)\n",
    "        \n",
    "        return output \n",
    "    \n",
    "    def final_block(x):\n",
    "        output = BatchNormalization(axis=chan_axis)(x)\n",
    "        output = Activation('relu')(output)\n",
    "        output = AveragePooling2D()(output)\n",
    "        output = Flatten()(output)\n",
    "        output = Dense(num_classes, activation='softmax')(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    x = Input(shape=input_shape)\n",
    "    output = Lambda(input_normalization)(x)\n",
    "    output = conv1(output)\n",
    "    \n",
    "    for i in range(n):\n",
    "        output = conv2(output, k, D)\n",
    "    \n",
    "    for i in range(n):\n",
    "        output = conv3(output, k, D)\n",
    "    \n",
    "    for i in range(n):\n",
    "        output = conv4(output, k, D)\n",
    "        \n",
    "    output = final_block(output)\n",
    "    \n",
    "    model = Model(x, output)\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 / 5\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      " 2560/48000 [>.............................] - ETA: 1:47 - loss: 1.3926 - acc: 0.6270"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0cb956d00ae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwrn_clone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-e2778a876dd5>\u001b[0m in \u001b[0;36mk_fold\u001b[0;34m(model_func, n_folds, x_tab, y_tab, epochs, batch)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtrain_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtrain_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b9b1e3baf2c8>\u001b[0m in \u001b[0;36mtrain_evaluate\u001b[0;34m(model, x_tab_tr, y_tab_tr, x_tab_te, y_tab_te, epochs, batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tab_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tab_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tab_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tab_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_fold(lambda: wrn_clone(k=2), 5, x_train, y_train, 10, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assumed that with both random data augmentation & dropout the network shouldn't overfit (badly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t, x_val, y_t, y_val = train_test_split(x_train, y_train, test_size=0.16, random_state=666, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "model = wrn_clone(k=2, D=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/234 [==============================] - 103s 437ms/step - loss: 0.6749 - acc: 0.7866 - val_loss: 0.5993 - val_acc: 0.8183\n",
      "Epoch 2/10\n",
      "235/234 [==============================] - 99s 422ms/step - loss: 0.3691 - acc: 0.8681 - val_loss: 0.3076 - val_acc: 0.8966\n",
      "Epoch 3/10\n",
      "235/234 [==============================] - 99s 423ms/step - loss: 0.3304 - acc: 0.8827 - val_loss: 0.6653 - val_acc: 0.7973\n",
      "Epoch 4/10\n",
      "235/234 [==============================] - 100s 425ms/step - loss: 0.3056 - acc: 0.8915 - val_loss: 0.2552 - val_acc: 0.9108\n",
      "Epoch 5/10\n",
      "235/234 [==============================] - 100s 426ms/step - loss: 0.2682 - acc: 0.9030 - val_loss: 0.2650 - val_acc: 0.9066\n",
      "Epoch 6/10\n",
      "235/234 [==============================] - 100s 428ms/step - loss: 0.2627 - acc: 0.9045 - val_loss: 0.2364 - val_acc: 0.9161\n",
      "Epoch 7/10\n",
      "235/234 [==============================] - 101s 428ms/step - loss: 0.2403 - acc: 0.9128 - val_loss: 0.2141 - val_acc: 0.9245\n",
      "Epoch 8/10\n",
      "235/234 [==============================] - 101s 429ms/step - loss: 0.2298 - acc: 0.9174 - val_loss: 0.2282 - val_acc: 0.9224\n",
      "Epoch 9/10\n",
      "235/234 [==============================] - 99s 421ms/step - loss: 0.2185 - acc: 0.9201 - val_loss: 0.1961 - val_acc: 0.9314\n",
      "Epoch 10/10\n",
      "235/234 [==============================] - 99s 422ms/step - loss: 0.2433 - acc: 0.9145 - val_loss: 0.2122 - val_acc: 0.9258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6df5614a8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_t, y_t, batch_size=256),\n",
    "                    steps_per_epoch=len(x_train) / 256, epochs=10,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/234 [==============================] - 95s 402ms/step - loss: 0.2183 - acc: 0.9240\n",
      "Epoch 2/10\n",
      "235/234 [==============================] - 94s 399ms/step - loss: 0.2004 - acc: 0.9273\n",
      "Epoch 3/10\n",
      "235/234 [==============================] - 98s 416ms/step - loss: 0.1914 - acc: 0.9314\n",
      "Epoch 4/10\n",
      "235/234 [==============================] - 96s 410ms/step - loss: 0.1850 - acc: 0.9327\n",
      "Epoch 5/10\n",
      "235/234 [==============================] - 96s 410ms/step - loss: 0.1846 - acc: 0.9341\n",
      "Epoch 6/10\n",
      "235/234 [==============================] - 97s 413ms/step - loss: 0.1799 - acc: 0.9356\n",
      "Epoch 7/10\n",
      "235/234 [==============================] - 95s 405ms/step - loss: 0.1762 - acc: 0.9365\n",
      "Epoch 8/10\n",
      "235/234 [==============================] - 95s 403ms/step - loss: 0.1721 - acc: 0.9380\n",
      "Epoch 9/10\n",
      "235/234 [==============================] - 95s 404ms/step - loss: 0.3183 - acc: 0.9103\n",
      "Epoch 10/10\n",
      "235/234 [==============================] - 95s 405ms/step - loss: 0.2099 - acc: 0.9262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd65cf72eb8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=256),\n",
    "                    steps_per_epoch=len(x_train) / 256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "235/234 [==============================] - 95s 406ms/step - loss: 0.1279 - acc: 0.9540\n",
      "Epoch 2/2\n",
      "235/234 [==============================] - 95s 402ms/step - loss: 0.1275 - acc: 0.9546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd65cb67828>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0005\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=256),\n",
    "                    steps_per_epoch=len(x_train) / 256, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/234 [==============================] - 96s 410ms/step - loss: 0.1205 - acc: 0.9563\n",
      "Epoch 2/5\n",
      "235/234 [==============================] - 94s 400ms/step - loss: 0.1196 - acc: 0.9568\n",
      "Epoch 3/5\n",
      "235/234 [==============================] - 94s 400ms/step - loss: 0.1205 - acc: 0.9566\n",
      "Epoch 4/5\n",
      "235/234 [==============================] - 94s 400ms/step - loss: 0.1129 - acc: 0.9589\n",
      "Epoch 5/5\n",
      "235/234 [==============================] - 94s 401ms/step - loss: 0.1158 - acc: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd65cad96d8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=256),\n",
    "                    steps_per_epoch=len(x_train) / 256, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/234 [==============================] - 94s 399ms/step - loss: 0.1122 - acc: 0.9600\n",
      "Epoch 2/5\n",
      "235/234 [==============================] - 94s 399ms/step - loss: 0.1083 - acc: 0.9608\n",
      "Epoch 3/5\n",
      "235/234 [==============================] - 94s 400ms/step - loss: 0.1172 - acc: 0.9584\n",
      "Epoch 4/5\n",
      "235/234 [==============================] - 94s 402ms/step - loss: 0.1130 - acc: 0.9587\n",
      "Epoch 5/5\n",
      "235/234 [==============================] - 94s 401ms/step - loss: 0.1087 - acc: 0.9608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd65cccac18>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.00005\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=256),\n",
    "                    steps_per_epoch=len(x_train) / 256, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/234 [==============================] - 100s 424ms/step - loss: 0.0826 - acc: 0.9708\n",
      "Epoch 2/5\n",
      "235/234 [==============================] - 98s 418ms/step - loss: 0.0766 - acc: 0.9718\n",
      "Epoch 3/5\n",
      "235/234 [==============================] - 99s 422ms/step - loss: 0.0735 - acc: 0.9732\n",
      "Epoch 4/5\n",
      "235/234 [==============================] - 101s 431ms/step - loss: 0.0765 - acc: 0.9717\n",
      "Epoch 5/5\n",
      "235/234 [==============================] - 101s 428ms/step - loss: 0.0733 - acc: 0.9736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f74a3bee400>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.00001\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=256),\n",
    "                    steps_per_epoch=len(x_train) / 256, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 ..., 8 1 5]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test)\n",
    "submission = np.argmax(result, axis=1)\n",
    "print(submission)\n",
    "with open('wrn-submission8.csv', 'w') as f:\n",
    "    f.write('Id,Class\\n')\n",
    "    for i, c in enumerate(submission):\n",
    "        f.write('{},{}\\n'.format(i, c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
